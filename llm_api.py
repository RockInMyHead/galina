"""
üåê API –î–õ–Ø –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò LLM –û–¢–í–ï–¢–û–í
–ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∏—Å—Ç–µ–º—ã
"""

from typing import Optional, Dict, List, Callable
import json
from professional_llm_system import (
    ProfessionalLLMProcessor,
    LLMResponse,
    ContentType
)


class LLMAPIClient:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ LLM
    
    –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    
    # 1. –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    client = LLMAPIClient()
    result = client.process("–í–∞—à LLM –æ—Ç–≤–µ—Ç")
    print(result.markdown)
    
    # 2. –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    client = LLMAPIClient(
        max_length=3000,
        similarity_threshold=0.8,
        verbose=False
    )
    
    # 3. –° –∫–∞—Å—Ç–æ–º–Ω—ã–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–º
    def my_handler(response):
        # –í–∞—à–∞ –∫–∞—Å—Ç–æ–º–Ω–∞—è –ª–æ–≥–∏–∫–∞
        return response
    
    result = client.process(
        "LLM –æ—Ç–≤–µ—Ç",
        custom_handler=my_handler
    )
    """
    
    def __init__(
        self,
        max_length: int = 2000,
        similarity_threshold: float = 0.70,
        verbose: bool = False
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            similarity_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (0-1)
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–æ–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.processor = ProfessionalLLMProcessor(verbose=verbose)
        self.processor.optimizer.max_length = max_length
        self.processor.duplicate_detector.similarity_threshold = similarity_threshold
        self.verbose = verbose
    
    def process(
        self,
        llm_response: str,
        title: str = "",
        custom_handler: Optional[Callable] = None
    ) -> 'ProcessedResponse':
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å LLM –æ—Ç–≤–µ—Ç
        
        Args:
            llm_response: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LLM
            title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            custom_handler: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Returns:
            ProcessedResponse –æ–±—ä–µ–∫—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        llm_response_obj = self.processor.process(llm_response, title)
        
        # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if custom_handler:
            llm_response_obj = custom_handler(llm_response_obj)
        
        # –°–æ–∑–¥–∞—Ç—å —É–¥–æ–±–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞
        processed = ProcessedResponse(
            llm_response_obj,
            self.processor
        )
        
        return processed
    
    def process_batch(
        self,
        llm_responses: List[Dict[str, str]],
        title_key: str = 'title',
        content_key: str = 'content'
    ) -> List['ProcessedResponse']:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ LLM –æ—Ç–≤–µ—Ç–æ–≤
        
        Args:
            llm_responses: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å LLM –æ—Ç–≤–µ—Ç–∞–º–∏
            title_key: –ö–ª—é—á –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
            content_key: –ö–ª—é—á –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ ProcessedResponse –æ–±—ä–µ–∫—Ç–æ–≤
        """
        results = []
        
        for item in llm_responses:
            title = item.get(title_key, '')
            content = item.get(content_key, '')
            
            result = self.process(content, title)
            results.append(result)
        
        return results


class ProcessedResponse:
    """
    –£–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º LLM
    """
    
    def __init__(self, llm_response_obj: LLMResponse, processor: ProfessionalLLMProcessor):
        self._response = llm_response_obj
        self._processor = processor
    
    @property
    def markdown(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å Markdown –≤—ã–≤–æ–¥"""
        return self._processor.get_markdown(self._response)
    
    @property
    def json(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
        return self._processor.get_json(self._response)
    
    @property
    def summary(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ"""
        return self._processor.get_summary(self._response)
    
    @property
    def html(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å HTML –≤—ã–≤–æ–¥ (–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ Markdown)"""
        return self._markdown_to_html(self.markdown)
    
    @property
    def plaintext(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å plain text"""
        return "\n\n".join([
            f"{chunk.title}\n{chunk.content}"
            for chunk in self._response.chunks
            if chunk.title or chunk.content
        ])
    
    @property
    def statistics(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return {
            'original_length': self._response.metadata['original_length'],
            'optimized_length': self._response.metadata['optimized_length'],
            'compression_ratio': self._response.deduplication_ratio,
            'chunks_count': len(self._response.chunks),
            'chunks_removed': self._response.metadata['chunks_removed'],
            'duplicates_found': self._response.metadata['duplicates_found'],
            'quality_score': self._response.quality_score,
            'processing_time': self._response.processing_time,
        }
    
    @property
    def chunks(self):
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —á–∞–Ω–∫–∏"""
        return self._response.chunks
    
    def get_by_type(self, content_type: ContentType) -> List:
        """–ü–æ–ª—É—á–∏—Ç—å —á–∞–Ω–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        return [c for c in self._response.chunks if c.type == content_type]
    
    def save_markdown(self, filepath: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Markdown —Ñ–∞–π–ª"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(self.markdown)
    
    def save_json(self, filepath: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON —Ñ–∞–π–ª"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.json, f, ensure_ascii=False, indent=2)
    
    def print_statistics(self) -> None:
        """–í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        stats = self.statistics
        
        print("\n" + "="*60)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        print("="*60)
        print(f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞:    {stats['original_length']:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: {stats['optimized_length']:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"–°–∂–∞—Ç–∏–µ:                 {stats['compression_ratio']:.1%}")
        print(f"–ë–ª–æ–∫–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:       {stats['chunks_count']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –±–ª–æ–∫–æ–≤:        {stats['chunks_removed']}")
        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:  {stats['duplicates_found']}")
        print(f"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:       {stats['quality_score']:.1%}")
        print(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:       {stats['processing_time']:.2f}—Å")
    
    def _markdown_to_html(self, markdown: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ Markdown –≤ HTML"""
        import re
        
        html = markdown
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        html = re.sub(r'^### (.*?)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
        html = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
        html = re.sub(r'^# (.*?)$', r'<h1>\1</h1>', html, flags=re.MULTILINE)
        
        # –ñ–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
        html = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html)
        
        # –ö—É—Ä—Å–∏–≤
        html = re.sub(r'\*(.*?)\*', r'<em>\1</em>', html)
        
        # –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        html = html.replace('\n\n', '</p><p>')
        html = f'<p>{html}</p>'
        
        return html
    
    def __str__(self) -> str:
        """–°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"""
        return self.markdown
    
    def __repr__(self) -> str:
        """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        return (
            f"ProcessedResponse(chunks={len(self.chunks)}, "
            f"quality={self.statistics['quality_score']:.1%}, "
            f"compression={self.statistics['compression_ratio']:.1%})"
        )


# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================================

def quick_process(llm_response: str, title: str = "") -> ProcessedResponse:
    """
    –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ LLM –æ—Ç–≤–µ—Ç–∞ —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    
    Example:
        result = quick_process("–ú–æ–π LLM –æ—Ç–≤–µ—Ç")
        print(result.markdown)
    """
    client = LLMAPIClient()
    return client.process(llm_response, title)


def compare_responses(
    original: str,
    processed_response: ProcessedResponse
) -> None:
    """
    –°—Ä–∞–≤–Ω–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç—ã
    """
    print("\n" + "="*70)
    print("üîç –°–†–ê–í–ù–ï–ù–ò–ï –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û –ò –û–ë–†–ê–ë–û–¢–ê–ù–ù–û–ì–û –û–¢–í–ï–¢–û–í")
    print("="*70)
    
    print(f"\nüìè –†–ê–ó–ú–ï–†:")
    print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª: {len(original):,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: {processed_response.statistics['optimized_length']:,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –°–∂–∞—Ç–∏–µ: {processed_response.statistics['compression_ratio']:.1%}")
    
    print(f"\nüìä –ö–ê–ß–ï–°–¢–í–û:")
    print(f"   –ë–ª–æ–∫–æ–≤: {processed_response.statistics['chunks_count']}")
    print(f"   –£–¥–∞–ª–µ–Ω–æ –±–ª–æ–∫–æ–≤: {processed_response.statistics['chunks_removed']}")
    print(f"   –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {processed_response.statistics['duplicates_found']}")
    print(f"   –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {processed_response.statistics['quality_score']:.1%}")
    
    print(f"\n‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
    print(f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processed_response.statistics['processing_time']:.2f}—Å")


def create_integration_example():
    """
    –ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–∏—Å—Ç–µ–º—É
    """
    
    example_code = '''
# –ü—Ä–∏–º–µ—Ä 1: –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
from llm_api import quick_process

llm_response = "–í–∞—à –æ—Ç–≤–µ—Ç –æ—Ç LLM..."
result = quick_process(llm_response, title="–ú–æ–π –¥–æ–∫—É–º–µ–Ω—Ç")
print(result.markdown)


# –ü—Ä–∏–º–µ—Ä 2: –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
from llm_api import LLMAPIClient

client = LLMAPIClient(
    max_length=3000,
    similarity_threshold=0.75,
    verbose=True
)

result = client.process(llm_response, title="–î–æ–∫—É–º–µ–Ω—Ç")

# –ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
print(result.markdown)
print(result.json)
print(result.summary)
print(result.html)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
result.save_markdown("output.md")
result.save_json("output.json")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
result.print_statistics()


# –ü—Ä–∏–º–µ—Ä 3: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
responses = [
    {'title': '–î–æ–∫—É–º–µ–Ω—Ç 1', 'content': 'LLM –æ—Ç–≤–µ—Ç 1'},
    {'title': '–î–æ–∫—É–º–µ–Ω—Ç 2', 'content': 'LLM –æ—Ç–≤–µ—Ç 2'},
]

results = client.process_batch(responses)

for result in results:
    print(result.markdown)
    result.print_statistics()


# –ü—Ä–∏–º–µ—Ä 4: –ö–∞—Å—Ç–æ–º–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
def my_custom_handler(response):
    # –î–æ–±–∞–≤–∏—Ç—å –∫–∞—Å—Ç–æ–º–Ω—É—é –ª–æ–≥–∏–∫—É
    for chunk in response.chunks:
        if chunk.type.value == 'warning':
            chunk.importance = 1.0  # –°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏
    return response

result = client.process(
    llm_response,
    custom_handler=my_custom_handler
)
    '''
    
    return example_code


# ============================================================================
# –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° –ü–û–ü–£–õ–Ø–†–ù–´–ú–ò LLM –°–ï–†–í–ò–°–ê–ú–ò
# ============================================================================

class LLMIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ LLM —Å–µ—Ä–≤–∏—Å–∞–º–∏"""
    
    @staticmethod
    def process_openai_response(response: Dict) -> ProcessedResponse:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI API
        
        Example:
            import openai
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": "..."}]
            )
            result = LLMIntegration.process_openai_response(response)
        """
        client = LLMAPIClient()
        content = response['choices'][0]['message']['content']
        return client.process(content)
    
    @staticmethod
    def process_anthropic_response(response: Dict) -> ProcessedResponse:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Anthropic Claude"""
        client = LLMAPIClient()
        content = response['content'][0]['text']
        return client.process(content)
    
    @staticmethod
    def process_huggingface_response(response: str) -> ProcessedResponse:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç HuggingFace"""
        client = LLMAPIClient()
        return client.process(response)


if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
    print("\n" + "="*70)
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø LLM API")
    print("="*70)
    
    print("\nüìù –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:")
    print(create_integration_example())

