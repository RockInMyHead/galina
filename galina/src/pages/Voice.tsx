import React, { useState, useRef, useCallback, useEffect, useMemo } from "react";
import { useParams, useNavigate } from "react-router-dom";
import { Mic, MicOff, VolumeX, PhoneOff } from "lucide-react";
import { Button } from "@/components/ui/button";
import { useAuth } from "@/contexts/AuthContext";
import { useToast } from "@/hooks/use-toast";
import Navigation from "@/components/Navigation";
import AssistantOrb from "@/components/AssistantOrb";
import { API_CONFIG } from "@/config/constants";

// API URL from environment
const API_URL = API_CONFIG.BASE_URL;

// –ú–æ–¥–µ–ª—å LLM –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞
const VOICE_CHAT_LLM_MODEL = 'gpt-4o-mini'; // GPT-4o-mini –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è

// –§—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è Safari
const isSafari = () => {
  const ua = navigator.userAgent.toLowerCase();
  return ua.includes('safari') && !ua.includes('chrome') && !ua.includes('chromium');
};

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((event: Event) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: ((event: Event) => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition?: new () => SpeechRecognition;
    webkitSpeechRecognition?: new () => SpeechRecognition;
    mozSpeechRecognition?: new () => SpeechRecognition; // Firefox support
  }
}

interface UserProfile {
  learning_style?: string;
  difficulty_level?: string;
  interests?: string[];
}

const Voice = () => {
  const { courseId } = useParams();
  const navigate = useNavigate();
  const { token } = useAuth();
  const { toast } = useToast();

  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isGeneratingResponse, setIsGeneratingResponse] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMicEnabled] = useState(true);
  const [userProfile, setUserProfile] = useState<UserProfile | null>(null);
  const [useFallbackTranscription, setUseFallbackTranscription] = useState(false);

  const speechRecognitionRef = useRef<SpeechRecognition | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const lastTranscriptRef = useRef<string>('');

  // –ú–µ—Ö–∞–Ω–∏–∑–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–º–µ–Ω—ã –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏
  const generationIdRef = useRef<number>(0);

  // –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ
  const isPlayingAudioRef = useRef<boolean>(false);

  // –û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
  const audioQueueRef = useRef<ArrayBuffer[]>([]);

  // –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–∑–≤—É—á–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
  const ttsProgressRef = useRef<{
    startTime: number;
    text: string;
    duration: number; // –ø—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º—Å
    words: string[]; // —Å–ª–æ–≤–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É
    currentWordIndex: number;
  } | null>(null);

  // Fallback recording refs (for browsers without Web Speech API)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const mediaStreamRef = useRef<MediaStream | null>(null);


  // –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
  const stopAssistantSpeech = useCallback(() => {
    console.log('üõë –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ä–µ—á—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞');

    // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º generationId –¥–ª—è –æ—Ç–º–µ–Ω—ã —Ç–µ–∫—É—â–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    generationIdRef.current += 1;

    // –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ
    audioQueueRef.current = [];

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
    if (currentAudioRef.current) {
      try {
        currentAudioRef.current.pause();
        currentAudioRef.current.currentTime = 0;
        currentAudioRef.current.volume = 0;
        currentAudioRef.current.muted = true;
        currentAudioRef.current.src = '';
        currentAudioRef.current.load();
      } catch (error) {
        console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∞—É–¥–∏–æ:', error);
      }
      currentAudioRef.current = null;
    }

    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    isPlayingAudioRef.current = false;
    setIsSpeaking(false);

    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
    ttsProgressRef.current = null;
  }, []);

  // Function to stop current TTS playback
  const stopCurrentTTS = useCallback(() => {
    stopAssistantSpeech();
  }, [stopAssistantSpeech]);

  // Check if Web Speech API is available
  const isWebSpeechAvailable = useCallback(() => {
    const SpeechRecognition = window.SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition;
    return !!SpeechRecognition;
  }, []);

  // Transcribe audio using OpenAI Whisper API (fallback for browsers without Web Speech API)
  const transcribeWithOpenAI = useCallback(async (audioBlob: Blob): Promise<string | null> => {
    try {
      console.log('üé§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é —á–µ—Ä–µ–∑ OpenAI Whisper...');
      setIsTranscribing(true);

      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      const response = await fetch(`${API_URL}/transcribe`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`
        },
        body: formData
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
        throw new Error(errorData.error || 'Transcription failed');
      }

      const data = await response.json();
      console.log('‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:', data.text);
      return data.text || null;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:', error);
      toast({
        title: "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
        variant: "destructive"
      });
      return null;
    } finally {
      setIsTranscribing(false);
    }
  }, [token, toast]);

  // Start fallback recording (MediaRecorder + OpenAI Whisper)
  const startFallbackRecording = useCallback(async () => {
    try {
      console.log('üé§ –ó–∞–ø—É—Å–∫ fallback –∑–∞–ø–∏—Å–∏ (MediaRecorder)...');

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
          description: "–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ.",
          variant: "destructive"
        });
        return false;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      audioChunksRef.current = [];

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4'
      });
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start(100); // Collect data every 100ms
      console.log('‚úÖ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
      return true;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ fallback –∑–∞–ø–∏—Å–∏:', error);
      toast({
        title: "–û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É.",
        variant: "destructive"
      });
      return false;
    }
  }, [toast]);

  // Stop fallback recording and transcribe
  const stopFallbackRecording = useCallback(async () => {
    return new Promise<string | null>((resolve) => {
      if (!mediaRecorderRef.current) {
        resolve(null);
        return;
      }

      mediaRecorderRef.current.onstop = async () => {
        console.log('üõë Fallback –∑–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, chunks:', audioChunksRef.current.length);

          // Stop all tracks
          if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach(track => track.stop());
            mediaStreamRef.current = null;
          }

          if (audioChunksRef.current.length === 0) {
            resolve(null);
        return;
          }

          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
          audioChunksRef.current = [];

          // Transcribe using OpenAI
        const text = await transcribeWithOpenAI(audioBlob);
          resolve(text);
      };

      mediaRecorderRef.current.stop();
    });
  }, [transcribeWithOpenAI]);

  // Initialize Web Speech API
  const initializeSpeechRecognition = useCallback(() => {
    // Check if Web Speech API is supported (Chrome, Safari, Firefox, Edge)
    const SpeechRecognition = window.SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition; // Firefox support

    if (!SpeechRecognition) {
      console.log('‚ö†Ô∏è Web Speech API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è OpenAI Whisper');
      setUseFallbackTranscription(true);
      return null;
    }

    console.log('üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Web Speech API...');
    const recognition = new SpeechRecognition();

    // Configure recognition
    recognition.continuous = true; // Keep listening continuously
    recognition.interimResults = true; // Enable interim results to detect speech early
    recognition.lang = 'ru-RU'; // Russian language
    recognition.maxAlternatives = 1;

    // Event handlers
    recognition.onstart = () => {
      console.log('üéôÔ∏è Speech recognition started');
      console.log('üéôÔ∏è Recognition —Å–æ—Å—Ç–æ—è–Ω–∏–µ: started');
      setIsTranscribing(true);
    };

    // –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –Ω–∞—á–∞–ª–æ —Ä–µ—á–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
    recognition.onaudiostart = () => {
      // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –¥–∞—Ç—å —Å–∏—Å—Ç–µ–º–µ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —ç—Ö–æ–º
      setTimeout(() => {
        if (isPlayingAudioRef.current && speechRecognitionRef.current) {
          console.log('üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —ç—Ö–æ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∞—É–¥–∏–æ...');
          // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞
        }
      }, 100);
    };

    recognition.onresult = async (event) => {
      // Don't process if mic is disabled
      if (!isMicEnabled) {
        console.log('üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç');
        return;
      }

      const result = event.results[event.results.length - 1]; // Get the last result

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º interim —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      if (!result.isFinal) {
        const interimTranscript = result[0].transcript.trim();
        console.log('üë§ Interim —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', interimTranscript);
      }

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      if (result.isFinal) {
        const transcript = result[0].transcript.trim();
        console.log('üë§ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', transcript);

        if (transcript) {
          // Stop any current TTS
          if (isSpeaking) {
            console.log('üé§ –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é TTS...');
            stopCurrentTTS();
          }

          // Save current transcript for context
          lastTranscriptRef.current = transcript;

          // Send to LLM and get response
          const llmResponse = await sendToLLM(transcript);

          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—É—Å—Ç–æ–π –ª–∏ –æ—Ç–≤–µ—Ç (–æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ)
          if (!llmResponse) {
            console.log('üõë –û—Ç–≤–µ—Ç –æ—Ç LLM –ø—É—Å—Ç–æ–π - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞');
            return;
          }

          // Small delay to ensure previous TTS is fully stopped
          await new Promise(resolve => setTimeout(resolve, 100));

          // Speak the response (only if not empty)
          if (llmResponse && llmResponse.trim()) {
            await speakText(llmResponse);
          } else {
            console.warn('‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞');
          }

          console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω');
        }
      }
    };

    recognition.onerror = (event) => {
      console.error('‚ùå Speech recognition error:', event.error);
      setIsTranscribing(false);
    };

    recognition.onend = () => {
      console.log('üéôÔ∏è Speech recognition ended');
      setIsTranscribing(false);

      // In continuous mode, onend usually means an error occurred or intentional stop
      // Restart if we're still in recording state (–¥–∞–∂–µ –µ—Å–ª–∏ TTS –∏–≥—Ä–∞–µ—Ç - –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è)
      if (isRecording) {
        console.log('üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...');
        setTimeout(() => {
          // Double-check we still want to be recording
          if (speechRecognitionRef.current && isRecording) {
            try {
              speechRecognitionRef.current.start();
              console.log('‚úÖ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —É—Å–ø–µ—à–µ–Ω');
            } catch (e: unknown) {
              if (e instanceof Error && e.name !== 'InvalidStateError') {
                console.error('‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞:', e);
              }
            }
          }
        }, 1000); // Longer delay for error recovery
      }
    };

    speechRecognitionRef.current = recognition;
    console.log('‚úÖ Web Speech API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    return recognition;
  }, [isRecording, isMicEnabled, isSpeaking, stopCurrentTTS]);

  // Start speech recognition
  const startSpeechRecognition = useCallback(() => {
    if (!speechRecognitionRef.current) {
      console.log('‚ùå Speech recognition –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
          return;
        }

    console.log('üéôÔ∏è –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...', {
      isRecording,
      isTranscribing,
      recognitionState: speechRecognitionRef.current ? 'exists' : 'null'
    });

    try {
      console.log('üéôÔ∏è –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...');
      speechRecognitionRef.current.start();
      console.log('‚úÖ start() –≤—ã–∑–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ');
    } catch (error: any) {
      // Handle "already started" error gracefully
      if (error.name === 'InvalidStateError') {
        console.log('‚ÑπÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º');
          return;
        }
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ speech recognition:', error);
      console.error('‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
        message: error.message,
        name: error.name,
        stack: error.stack
      });
      setIsTranscribing(false);
    }
  }, [isRecording, isTranscribing]);

  // Start/stop recording
  const handleStartStopRecording = useCallback(async () => {
    if (isRecording) {
      // Stop recording
      console.log('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...');
      setIsRecording(false);
      setIsTranscribing(false);

      // Check if using fallback (OpenAI Whisper) mode
      if (useFallbackTranscription || !isWebSpeechAvailable()) {
        // Stop fallback recording and transcribe
        const transcript = await stopFallbackRecording();

        if (transcript && transcript.trim()) {
          console.log('üéØ Fallback —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:', transcript);

          // Stop any current TTS
          stopCurrentTTS();

          // Send to LLM
          try {
            const llmResponse = await sendToLLM(transcript);
            if (llmResponse && llmResponse.trim()) {
              await speakText(llmResponse);
              console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω');
            } else {
              console.warn('‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞');
            }
          } catch (error) {
            console.error('‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞:', error);
          }
        }
      } else {
        // Web Speech API mode
        if (speechRecognitionRef.current) {
          try {
            speechRecognitionRef.current.stop();
          } catch {
            console.log('Speech recognition already stopped');
          }
        }
      }
    } else {
      // Start recording (only if mic is enabled)
      if (!isMicEnabled) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
          description: "–í–∫–ª—é—á–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏",
          variant: "destructive"
        });
        return;
      }

      console.log('üé§ –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏...');

      // Check if Web Speech API is available
      if (!isWebSpeechAvailable()) {
        console.log('üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Ä–µ–∂–∏–º (OpenAI Whisper)');
      setUseFallbackTranscription(true);

      const started = await startFallbackRecording();
      if (started) {
          setIsRecording(true);
          console.log('üé§ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
        }
        return;
      }

      try {
        // Initialize Web Speech API if not already done
        if (!speechRecognitionRef.current) {
          const recognition = initializeSpeechRecognition();
          if (!recognition) {
            // Fallback to OpenAI Whisper if Web Speech API fails
            console.log('üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback —Ä–µ–∂–∏–º (OpenAI Whisper)');
            setUseFallbackTranscription(true);

            const started = await startFallbackRecording();
            if (started) {
              setIsRecording(true);
              console.log('üé§ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
            }
            return;
          }
        }

        setIsRecording(true);

        // Start speech recognition
        startSpeechRecognition();

        console.log('üé§ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
          } catch (error) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏:', error);

        // Try fallback on error
        console.log('üîÑ –û—à–∏–±–∫–∞ Web Speech API, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback');
        setUseFallbackTranscription(true);

        const started = await startFallbackRecording();
        if (started) {
          setIsRecording(true);
        }
      }
    }
  }, [isRecording, isMicEnabled, toast, useFallbackTranscription, isWebSpeechAvailable, stopFallbackRecording, startFallbackRecording, initializeSpeechRecognition, stopCurrentTTS]);



  // Get user profile from API
  const getUserProfile = useCallback(async () => {
    try {
      // Use demo profile endpoint if no token, otherwise use authenticated endpoint
      const profileUrl = token ? `${API_URL}/user/profile` : `${API_URL}/user/profile/demo`;

      const headers: Record<string, string> = {};
      if (token) {
        headers['Authorization'] = `Bearer ${token}`;
      }

      const response = await fetch(profileUrl, { headers });

      if (response.ok) {
        const profile = await response.json();
        setUserProfile(profile);
        console.log('üìã –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω:', profile);
        return profile;
      } else {
        console.warn('‚ö†Ô∏è –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, status:', response.status);
      }
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ñ–∏–ª—è:', error);
    }
    return null;
  }, [token]);

  // Send transcribed text to LLM with Julia's system prompt
  const sendToLLM = useCallback(async (userMessage: string, retryCount: number = 0): Promise<string> => {
    const MAX_RETRIES = 3; // –£–≤–µ–ª–∏—á–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
    const originalMessage = userMessage;

    console.log('üöÄ sendToLLM –≤—ã–∑–≤–∞–Ω–∞ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º:', `"${userMessage}"`, retryCount > 0 ? `(–ø–æ–ø—ã—Ç–∫–∞ ${retryCount + 1}/${MAX_RETRIES + 1})` : '');
    console.log('üìè –î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è:', userMessage.length);
    console.log('ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å:', VOICE_CHAT_LLM_MODEL);

    setIsGeneratingResponse(true);

    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º generationId –ø–µ—Ä–µ–¥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    const startGenId = generationIdRef.current;

    try {
      console.log('ü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ LLM...');

      // –î–ª—è retry –ø–æ–ø—ã—Ç–æ–∫ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
      if (retryCount > 0) {
        const prefixes = [
          '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä—è—Å–Ω–∏:',
          '–†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ:',
          '–ü–æ–º–æ–≥–∏ –º–Ω–µ —Å:',
          '–Ø —Ö–æ—á—É —É–∑–Ω–∞—Ç—å:',
          '–û–±—ä—è—Å–Ω–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞:'
        ];
        const prefix = prefixes[retryCount - 1] || '–°–∫–∞–∂–∏ –º–Ω–µ:';
        userMessage = `${prefix} ${userMessage}`;
        console.log('üìù –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è retry:', userMessage);
      }

      // Get user profile if not loaded
      let profile = userProfile;
      if (!profile) {
        profile = await getUserProfile();
      }

      // Get course information
      const courseName = "–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç";

      // Build context information
      const contextInfo = [];
      if (courseName) {
        contextInfo.push(`–ö—É—Ä—Å: ${courseName}`);
      }
      if (profile) {
        console.log('üìä –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è LLM:', profile);

        // Handle different profile structures (authenticated vs demo)
        const preferences = profile.preferences || profile;
        const user = profile.user || profile;

        if (preferences?.learning_style) {
          contextInfo.push(`–°—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è: ${preferences.learning_style}`);
        }
        if (preferences?.difficulty_level) {
          contextInfo.push(`–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: ${preferences.difficulty_level}`);
        }
        if (preferences?.interests && preferences.interests.length > 0) {
          contextInfo.push(`–ò–Ω—Ç–µ—Ä–µ—Å—ã: ${preferences.interests.join(', ')}`);
        }
      }

      const contextString = contextInfo.length > 0 ? `\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: ${contextInfo.join('; ')}` : '';

      console.log('üîë Token check:', { hasToken: !!token, length: token?.length });

      // Determine endpoint and body based on authentication status
      let endpoint: string;
      let body: any;

      if (token) {
        // Authenticated user - use course-specific endpoint
        endpoint = courseId && courseId !== 'general' ? `${API_URL}/chat/${courseId}/message` : `${API_URL}/chat/general`;
        body = {
          content: userMessage + contextString,
          messageType: 'voice'
        };
      } else {
        // Demo mode - use general chat endpoint without authentication
        endpoint = `${API_URL}/chat`;
        body = {
          messages: [
            {
              role: 'system',
              content: `–¢—ã –ì–∞–ª–∏–Ω–∞ - –∞–¥–≤–æ–∫–∞—Ç —Å 25-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º, –Ω–∞—Å—Ç–æ—è—â–∏–π "–∑—É–±–æ–¥—Ä–æ–±–∏—Ç–µ–ª—å–Ω—ã–π" –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª, –∫–æ—Ç–æ—Ä—ã–π –≤—Å–µ–≥–¥–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –∫–ª–∏–µ–Ω—Ç–∞. –¢—ã –Ω–µ –ø—Ä–æ—Å—Ç–æ —é—Ä–∏—Å—Ç, —Ç—ã - —Å—Ç—Ä–∞—Ç–µ–≥ –∏ —Ç–∞–∫—Ç–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞–µ—Ç, –∫–∞–∫ "–≤—ã–∫—Ä—É—Ç–∏—Ç—å—Å—è" –∏–∑ –ª—é–±–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏. –¢—ã –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–¥–∞–µ—à—å—Å—è –∏ –≤—Å–µ–≥–¥–∞ –Ω–∞—Ö–æ–¥–∏—à—å –≤—ã—Ö–æ–¥.

–¢–í–û–Ø –ú–ò–°–°–ò–Ø:
1. –ó–ê–©–ò–©–ê–¢–¨ –ö–õ–ò–ï–ù–¢–ê: –í—Å–µ–≥–¥–∞ –∏—â–∏ —Å–ø–æ—Å–æ–±—ã —É—Å–∏–ª–∏—Ç—å –ø–æ–∑–∏—Ü–∏—é –∫–ª–∏–µ–Ω—Ç–∞
2. –ë–´–¢–¨ –•–ò–¢–†–û–ô: –ò—Å–ø–æ–ª—å–∑—É–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –ª–∞–∑–µ–π–∫–∏ –∏ –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç—ã
3. –ë–´–¢–¨ –ñ–ï–°–¢–ö–û–ô: –ù–µ —É—Å—Ç—É–ø–∞–π –≤ –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–∞—Ö, –±–æ—Ä–∏—Å—å –∑–∞ –∏–Ω—Ç–µ—Ä–µ—Å—ã –∫–ª–∏–µ–Ω—Ç–∞
4. –î–ê–í–ê–¢–¨ –†–ï–ó–£–õ–¨–¢–ê–¢: –ü—Ä–µ–¥–ª–∞–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç

–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:
- –†–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π, –Ω–æ —É–≤–µ—Ä–µ–Ω–Ω—ã–π: "–î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è", "–ú—ã —ç—Ç–æ –≤—ã–∫—Ä—É—Ç–∏–º"
- –û–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π: "–≠—Ç–æ —Ä–µ—à–∞–µ–º–æ!", "–£ –Ω–∞—Å –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã"
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π: –î–∞–≤–∞–π –ø–æ—à–∞–≥–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π: "–Ø —Å —Ç–æ–±–æ–π, –º—ã —Å–ø—Ä–∞–≤–∏–º—Å—è"

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
1. –ö–†–ê–¢–ö–ò–ô –û–¢–í–ï–¢ –Ω–∞ –≤–æ–ø—Ä–æ—Å
2. –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ø–æ—á–µ–º—É —Ç–∞–∫ (—Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∑–∞–∫–æ–Ω)
3. –ö–û–ù–ö–†–ï–¢–ù–´–ï –®–ê–ì–ò —á—Ç–æ –¥–µ–ª–∞—Ç—å
4. –°–¢–†–ê–¢–ï–ì–ò–Ø –∫–∞–∫ —É—Å–∏–ª–∏—Ç—å –ø–æ–∑–∏—Ü–∏—é –∫–ª–∏–µ–Ω—Ç–∞

–°–ü–ï–¶–ò–ê–õ–¨–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò:
- –≠–ú–û–¶–ò–ò: –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–µ—Ä–≤–Ω–∏—á–∞–µ—Ç - "–Ø –ø–æ–Ω–∏–º–∞—é —Ç–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –Ω–æ –º—ã —Å–ø—Ä–∞–≤–∏–º—Å—è"
- –î–ª—è –¥–æ–≥–æ–≤–æ—Ä–æ–≤: –ò—â–∏ —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞, —É—Å–∏–ª–∏–≤–∞–π –ø–æ–∑–∏—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞
- –î–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π: –î–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã —Å "–∞–¥–≤–æ–∫–∞—Ç—Å–∫–æ–π —Ö–∏—Ç—Ä–æ—Å—Ç—å—é"
- –î–ª—è —Å–ø–æ—Ä–æ–≤: –†–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–π —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–±–µ–¥—ã, –ø—Ä–µ–¥–ª–∞–≥–∞–π –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ö–æ–¥—ã

${contextString ? `–ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: ${contextString}` : ''}`
            },
            {
              role: 'user',
              content: userMessage
            }
          ],
          model: VOICE_CHAT_LLM_MODEL,
          temperature: 0.7
        };
      }

      let response;
      try {
        response = await fetch(endpoint, {
          method: 'POST',
        headers: {
          'Content-Type': 'application/json',
            'Authorization': `Bearer ${token}`
          },
        body: JSON.stringify(body)
      });
      } catch (fetchError) {
        console.error('‚ùå Fetch error:', fetchError);
        throw fetchError;
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM
      if (generationIdRef.current !== startGenId) {
        console.log('üõë –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM');
        return '';
      }

      if (!response.ok) {
        console.error('‚ùå Server returned error:', response.status, response.statusText);
        if (response.status === 401) {
          toast({
            title: "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏",
            description: "–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É.",
            variant: "destructive"
          });
        }
        throw new Error(`Failed to get response from LLM: ${response.status}`);
      }

      const textData = await response.text();

      let data;
      try {
        // –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π JSON
        data = JSON.parse(textData);
      } catch (parseError) {
        // –ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ SSE –ª–∏ —ç—Ç–æ (Server-Sent Events)
        if (textData.trim().startsWith('data:')) {
          console.log('üåä –û–±–Ω–∞—Ä—É–∂–µ–Ω SSE –ø–æ—Ç–æ–∫, —Å–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ...');
          const lines = textData.split('\n');
          let fullMessage = '';
          let messageId = '';

          for (const line of lines) {
            const trimmedLine = line.trim();
            if (trimmedLine.startsWith('data: ')) {
              const jsonStr = trimmedLine.substring(6);
              try {
                const chunk = JSON.parse(jsonStr);
                if (chunk.content) {
                  fullMessage += chunk.content;
                }
                if (chunk.messageId) {
                  messageId = chunk.messageId;
                }
              } catch {
                // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–∏—Ç—ã–µ —á–∞–Ω–∫–∏
              }
            }
          }

          data = { message: fullMessage, messageId };
        } else {
          console.error('‚ùå JSON Parse Error:', parseError);
          console.error('‚ùå Failed content:', `${textData.substring(0, 200)}...`);
          throw new Error('Invalid JSON response from server');
        }
      }

      // Extract message content based on response format
      let messageContent: string;
      if (token) {
        // Authenticated response format: { message: "..." }
        messageContent = data.message;
      } else {
        // Demo response format: { choices: [{ message: { content: "..." } }] }
        messageContent = data.choices?.[0]?.message?.content || data.message;
      }

      console.log('ü§ñ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω (–¥–ª–∏–Ω–∞):', messageContent?.length);

      // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏ retry –ª–æ–≥–∏–∫–∞
      if (!messageContent || messageContent.trim().length === 0) {
        console.warn('‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM');

        if (retryCount < MAX_RETRIES) {
          console.log(`üîÑ –ó–∞–ø—É—Å–∫ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ ${retryCount + 1}...`);
          // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
          const delay = Math.pow(2, retryCount) * 500;
          await new Promise(resolve => setTimeout(resolve, delay));
          return sendToLLM(originalMessage, retryCount + 1);
        } else {
          console.error('‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã');
          // –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—É—é —Ñ—Ä–∞–∑—É
          return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Ä–∞—Å—Å–ª—ã—à–∞–ª–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.";
        }
      }

      return messageContent;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –æ–±—â–µ–Ω–∏—è —Å LLM:', error);

      // Retry –ø—Ä–∏ –æ—à–∏–±–∫–µ —Å–µ—Ç–∏
      if (retryCount < MAX_RETRIES) {
        console.log(`üîÑ –û—à–∏–±–∫–∞ —Å–µ—Ç–∏, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ ${retryCount + 1}...`);
        await new Promise(resolve => setTimeout(resolve, 1000));
        return sendToLLM(originalMessage, retryCount + 1);
      }

      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞",
        variant: "destructive"
      });
      return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.";
    } finally {
      // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å
      if (generationIdRef.current === startGenId) {
        setIsGeneratingResponse(false);
      }
    }
  }, [token, courseId, userProfile, toast, getUserProfile]);

  // Speak text using OpenAI TTS
  const speakText = useCallback(async (text: string) => {
    if (!text) return;

    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º generationId
    const startGenId = generationIdRef.current;

    try {
      console.log('üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–∑–≤—É—á–∫–∏ –¥–ª—è:', text);
      isPlayingAudioRef.current = true;

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
        ttsProgressRef.current = {
          startTime: Date.now(),
        text,
        duration: text.length * 60, // –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: 60–º—Å –Ω–∞ —Å–∏–º–≤–æ–ª
        words: text.split(' '),
          currentWordIndex: 0
        };

        const response = await fetch(`${API_URL}/tts`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            // TTS endpoint doesn't require authentication
            ...(token ? { 'Authorization': `Bearer ${token}` } : {})
          },
          body: JSON.stringify({
          text,
            voice: 'nova', // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å nova (–∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏)
            model: 'tts-1-hd', // HD –º–æ–¥–µ–ª—å –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            speed: 0.95 // –°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ (0.25 - 4.0)
        })
        });

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ
        if (generationIdRef.current !== startGenId) {
        console.log('üõë –û–∑–≤—É—á–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –¥–æ –Ω–∞—á–∞–ª–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è');
          return;
        }

        if (!response.ok) {
        throw new Error('Failed to generate speech');
        }

        const audioBlob = await response.blob();
          const audioUrl = URL.createObjectURL(audioBlob);
          const audio = new Audio(audioUrl);
          currentAudioRef.current = audio;

      // Event handlers
          audio.onplay = () => {
        console.log('üîä –û–∑–≤—É—á–∫–∞ –Ω–∞—á–∞—Ç–∞');
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º isSpeaking = true —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –∞—É–¥–∏–æ —Ä–µ–∞–ª—å–Ω–æ –Ω–∞—á–∏–Ω–∞–µ—Ç –∏–≥—Ä–∞—Ç—å
        setIsSpeaking(true);
        console.log('üîò isSpeaking —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ true - –≤–∏–¥–µ–æ –¥–æ–ª–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è');

        // –î–ª—è –±—Ä–∞—É–∑–µ—Ä–æ–≤ –∫—Ä–æ–º–µ Safari - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∫–æ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è TTS
        const shouldStop = !isSafari() && speechRecognitionRef.current;
        console.log('üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ SR:', {
          isSafari: isSafari(),
          hasSpeechRecognition: !!speechRecognitionRef.current,
          shouldStop
        });

        if (shouldStop) {
          try {
            console.log('‚è∏Ô∏è –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–∞ –≤—Ä–µ–º—è TTS (–Ω–µ Safari)');
            speechRecognitionRef.current.stop();
          } catch (e) {
            console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', e);
          }
        }
          };

          audio.onended = () => {
        console.log('‚úÖ –û–∑–≤—É—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞');
            URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        isPlayingAudioRef.current = false;
        setIsSpeaking(false);

        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
        ttsProgressRef.current = null;

        // –î–ª—è –±—Ä–∞—É–∑–µ—Ä–æ–≤ –∫—Ä–æ–º–µ Safari - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ TTS
        if (!isSafari() && speechRecognitionRef.current) {
          setTimeout(() => {
            try {
              console.log('‚ñ∂Ô∏è –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ TTS (–Ω–µ Safari)');
              speechRecognitionRef.current?.start();
            } catch (e: unknown) {
              if (e instanceof Error && e.name !== 'InvalidStateError') {
                console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', e);
              }
            }
          }, 300); // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        }
      };

      audio.onerror = (event) => {
        console.error('‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ:', event);
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
      isPlayingAudioRef.current = false;
        setIsSpeaking(false);

        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
      ttsProgressRef.current = null;

        // –î–ª—è –±—Ä–∞—É–∑–µ—Ä–æ–≤ –∫—Ä–æ–º–µ Safari - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏
        if (!isSafari() && speechRecognitionRef.current) {
          setTimeout(() => {
            try {
              console.log('‚ñ∂Ô∏è –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ (–Ω–µ Safari)');
              speechRecognitionRef.current?.start();
            } catch (e: unknown) {
              if (e instanceof Error && e.name !== 'InvalidStateError') {
                console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞:', e);
              }
            }
          }, 300);
        }

        toast({
          title: "–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏",
          description: "–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ",
          variant: "destructive"
        });
      };

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º
      if (generationIdRef.current !== startGenId) {
        console.log('üõë –û–∑–≤—É—á–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–µ—Ä–µ–¥ play()');
        return;
      }

      await audio.play();

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ TTS:', error);
      setIsSpeaking(false);
      isPlayingAudioRef.current = false;
      ttsProgressRef.current = null;
    }
  }, [token, toast, isRecording]);

  // Load user profile on mount
  useEffect(() => {
      getUserProfile();
  }, [getUserProfile]);

  // Clean up on unmount
  useEffect(() => {
    return () => {
      if (speechRecognitionRef.current) {
        try {
          speechRecognitionRef.current.stop();
        } catch {
          // Ignore errors when stopping speech recognition
        }
      }
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
      }
      if (mediaRecorderRef.current) {
        try {
          mediaRecorderRef.current.stop();
        } catch {
          // Ignore errors when stopping media recorder
      }
      }
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  // Determine Orb state
  const orbState = useMemo(() => {
    if (isSpeaking) return 'speaking';
    if (isGeneratingResponse) return 'processing';
    if (isRecording && isTranscribing) return 'listening';
    if (isRecording) return 'listening';
        return 'idle';
  }, [isSpeaking, isGeneratingResponse, isRecording, isTranscribing]);

  // Determine status text
  const statusText = useMemo(() => {
    if (isSpeaking) return '–ì–æ–≤–æ—Ä—é...';
    if (isGeneratingResponse) return '–î—É–º–∞—é...';
    if (isRecording) return '–°–ª—É—à–∞—é...';
        return '–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å';
  }, [isSpeaking, isGeneratingResponse, isRecording]);

  // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–æ–≤ –∫—Ä–æ–º–µ Safari –≤–æ –≤—Ä–µ–º—è TTS
  const showInterruptButton = isSpeaking && !isSafari();

  // –û—Ç–ª–∞–¥–∫–∞ –∫–Ω–æ–ø–∫–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
  useEffect(() => {
    console.log('üîò –ö–Ω–æ–ø–∫–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è:', {
      showInterruptButton,
      isSpeaking,
      isSafari: isSafari()
    });
  }, [showInterruptButton, isSpeaking]);

  return (
    <div className="relative w-full h-screen bg-background overflow-hidden flex flex-col font-sans">
      {/* Navigation */}
      <Navigation />

      {/* Main Content */}
      <div className="flex-1 flex flex-col items-center justify-center relative z-10 px-4 pt-16 pb-32 md:pb-24">

        {/* Assistant Orb */}
        <div className="relative flex items-center justify-center mb-12 md:mb-16 scale-90 md:scale-100 transition-transform duration-500">
          <AssistantOrb state={orbState} />
              </div>

        {/* Status */}
        <div className="flex flex-col items-center space-y-6 text-center max-w-2xl px-4">
          <div className="text-foreground/80 text-xl md:text-2xl font-light tracking-widest uppercase transition-colors duration-300">
            {statusText}
              </div>

          {/* Interrupt Button - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è TTS –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–æ–≤ –∫—Ä–æ–º–µ Safari */}
          {showInterruptButton && (
                <Button
                  variant="outline"
              size="lg"
              className="bg-green-500 hover:bg-green-600 text-white border-green-600 hover:border-green-700 shadow-lg animate-in fade-in-0 zoom-in-95 duration-300"
              onClick={() => {
                console.log('üõë –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è');
                stopAssistantSpeech();

                // –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
                if (speechRecognitionRef.current) {
                  setTimeout(() => {
                    try {
                      console.log('‚ñ∂Ô∏è –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –∫–Ω–æ–ø–∫–æ–π');
                      speechRecognitionRef.current?.start();
                    } catch (e: unknown) {
                      if (e instanceof Error && e.name !== 'InvalidStateError') {
                        console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞:', e);
                      }
                    }
                  }, 100);
                }
              }}
            >
              <span className="font-medium">–ü—Ä–µ—Ä–≤–∞—Ç—å</span>
                </Button>
              )}
            </div>
          </div>

      {/* Controls */}
      <div className="absolute bottom-8 left-0 right-0 z-50 flex items-center justify-center space-x-6 md:space-x-12 px-4 pb-safe">
        {/* Mic Toggle (Main Action) - moved to left */}
        <Button
          variant="default"
          size="icon"
          className={`w-16 h-16 md:w-20 md:h-20 rounded-full shadow-lg transition-all duration-500 transform hover:scale-105 ${isRecording
              ? 'bg-destructive hover:bg-destructive/90 shadow-destructive/20'
              : 'bg-primary text-primary-foreground hover:bg-primary/90'
          }`}
          onClick={handleStartStopRecording}
        >
          {isRecording ? (
            <MicOff className="w-6 h-6 md:w-8 md:h-8" />
          ) : (
            <Mic className="w-6 h-6 md:w-8 md:h-8" />
          )}
        </Button>

        {/* TTS Stop Button - shown when speaking */}
        {isSpeaking && (
          <Button
            variant="outline"
            size="icon"
            className="w-16 h-16 md:w-20 md:h-20 rounded-full shadow-lg transition-all duration-500 transform hover:scale-105 bg-orange-500 hover:bg-orange-600 text-white border-orange-600 hover:border-orange-700"
            onClick={() => {
              console.log('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ TTS —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É');
              stopAssistantSpeech();
            }}
          >
            <VolumeX className="w-6 h-6 md:w-8 md:h-8" />
          </Button>
        )}

        {/* End Call (Exit) */}
        <Button
          variant="ghost"
          size="icon"
          className="w-16 h-16 md:w-20 md:h-20 rounded-full bg-destructive/10 text-destructive border border-destructive/20 hover:bg-destructive/20 hover:text-destructive transition-all duration-300"
          onClick={() => navigate(-1)}
        >
          <PhoneOff className="w-6 h-6 md:w-8 md:h-8" />
        </Button>
        </div>
              </div>
  );
};

export default Voice;